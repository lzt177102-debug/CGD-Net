import os
import time
import json
import argparse
from typing import Dict, List, Tuple

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR
from tqdm import tqdm

from torch_geometric.loader import DataLoader
from torch_scatter import scatter_add

# è‡ªå®šä¹‰å·¥å…·ç±»/å‡½æ•°ï¼ˆä» src.utils.utils å¯¼å…¥ï¼‰
from src.utils.utils import (
    makedirs, 
    load_model, 
    convert_time_units, 
    get_max_gpu_memory_usage,
    AverageMeter,
    load_yaml_config
)

# æ•°æ®ç›¸å…³
from RSGCN_DataLoader import GraphDataBuilder, GraphDataLoaderManager

# æ¨¡å‹å®šä¹‰
from src.networks.GraphMamba import GraphGDP
from src.networks.GCN import GraphGDP_GCN
from src.networks.GraphGPS import GraphGDP_GraphGPS
from src.networks.Graphormer import GraphGDP_Graphormer

# æŸå¤±å‡½æ•°
from src.losses.dual_regression_loss import DualRegressionLoss

# è¯„ä¼°æŒ‡æ ‡
from src.metrics.metrics import (
    r2_score,
    mae_score
)



# ==================== è®­ç»ƒå™¨ç±»ï¼ˆæ ¸å¿ƒå°è£…ï¼Œæ”¯æŒä»YAMLåŠ è½½å­¦ä¹ ç‡ç­–ç•¥ä¸å‚æ•°ï¼‰ ====================
class GraphGDPTrainer:
    """GraphGDP æ¨¡å‹è®­ç»ƒå™¨ï¼ˆæå–æå‰ç”Ÿæˆçš„å¯¹æ•°æ ‡ç­¾ + MAE/RÂ² æŒ‡æ ‡ + é…ç½®åŒ–å­¦ä¹ ç‡ç­–ç•¥ + 50è½®åå¯ç”¨ä¸€è‡´æ€§æŸå¤±ï¼‰"""
    def __init__(self, config, device):
        self.config = config
        self.device = device
        self.epoch = 0
        self.best_val_r2 = -float('inf')  # æœ€ä¼˜æŒ‡æ ‡æ”¹ä¸ºRÂ²ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
        self.patience_counter = 0
        # å­¦ä¹ ç‡ç­–ç•¥æ ‡è¯†ï¼ˆç”¨äºåç»­è°ƒç”¨åˆ¤æ–­ï¼‰
        self.lr_scheduler_type = self.config.get('lr_scheduler_type', 'ReduceLROnPlateau')
        # æ–°å¢ï¼šæœ€ä¼˜æ¨¡å‹è®°å½•èµ·å§‹è½®æ•°é˜ˆå€¼ï¼ˆå›ºå®šä¸º50è½®ï¼Œå¯é…ç½®åŒ–æ‰©å±•ï¼‰
        self.best_model_start_epoch = 50
        
        # å‚è€ƒä»£ç é£æ ¼ï¼šç”Ÿæˆå”¯ä¸€æ—¶é—´æˆ³ï¼ˆä»…ç”¨äºå®éªŒç›®å½•å‘½åï¼Œæ–‡ä»¶æ— æ—¶é—´æˆ³ï¼‰
        self.timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())
        
        # ã€æ ¸å¿ƒã€‘åˆå§‹åŒ–æœ€æ–°YAMLè¦æ±‚çš„ç›®å½•ç»“æ„
        self._init_exp_dir()
        
        # æ„å»ºæ•°æ®ç›¸å…³ï¼ˆä¿®æ”¹ï¼šä»…åŠ è½½è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼‰
        self.train_dataset, self.val_dataset = self._build_dataset()
        self.train_loader, self.val_loader = self._build_dataloaders()
        
        # æ„å»ºæ¨¡å‹ç›¸å…³ï¼ˆå«ä»YAMLåŠ è½½å­¦ä¹ ç‡ç­–ç•¥ä¸å‚æ•°ï¼‰
        self.model, self.criterion, self.optimizer, self.scheduler = self._build_model_components()
        
        # æ–°å¢ï¼šè°ƒç”¨ç®€æ´ç‰ˆload_modelåŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆä»YAMLé…ç½®è¯»å–å‚æ•°ï¼‰
        if self.config['load_pretrained']:
            print(f"\n===== åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆè·¯å¾„ï¼š{self.config['pretrained_model_path']}ï¼‰ =====")
            self.model = load_model(
                model=self.model,
                checkpoint_path=self.config['pretrained_model_path'],
                multi_gpu=self.config['multi_gpu']
            )
            # ç¡®ä¿æ¨¡å‹ç§»è‡³æŒ‡å®šè®¾å¤‡ï¼ˆå…¼å®¹å¤šGPUï¼‰
            self.model = self.model.to(self.device)
            print(f"ğŸ‰ é¢„è®­ç»ƒæ¨¡å‹åŠ è½½å®Œæˆï¼")
        
        # è®­ç»ƒæ—¥å¿—
        self.train_log = self._load_train_log()
        
        # æ–°å¢ï¼šæ˜¾å­˜å’Œæ—¶é—´ç»Ÿè®¡ï¼ˆæ ¸å¿ƒï¼šè®°å½•å³°å€¼æ˜¾å­˜ã€æ¯è½®æ—¶é—´ã€æ€»æ—¶é—´ï¼‰
        self.total_training_start = 0.0  # æ€»è®­ç»ƒå¼€å§‹æ—¶é—´æˆ³
        self.total_training_time = 0.0  # æ€»è®­ç»ƒæ—¶é—´ï¼ˆç§’ï¼‰
        self.epoch_train_times = []  # æ¯è½®è®­ç»ƒæ—¶é—´ï¼ˆç§’ï¼‰
        self.max_gpu_memory_used = 0.0  # æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹çš„æœ€å¤§æ˜¾å­˜å ç”¨ï¼ˆMBï¼‰
        self.epoch_gpu_memories = []  # æ¯è½®è®­ç»ƒçš„å³°å€¼æ˜¾å­˜å ç”¨ï¼ˆMBï¼‰

    def _init_exp_dir(self):
        """ã€ç²¾å‡†åŒ¹é…ã€‘åˆå§‹åŒ–ç›®å½•ç»“æ„ï¼š./result/exp_æ—¶é—´æˆ³/ å†…å«config/logs/models"""
        # 1. æ ¹ç›®å½•ï¼š./resultï¼ˆæœ€æ–°YAMLæŒ‡å®šï¼Œç¡®ä¿å­˜åœ¨ï¼‰
        self.result_root = makedirs(self.config['output_dir'])
        
        # 2. æ ¸å¿ƒï¼šåˆ›å»ºå¸¦æ—¶é—´æˆ³çš„å®éªŒç›®å½• ./result/exp_20251228_123456/
        self.exp_dir = makedirs(os.path.join(self.result_root, f'exp_{self.timestamp}'))
        
        # 3. å®éªŒç›®å½•ä¸‹åˆ›å»ºå­ç›®å½•ï¼ˆconfig/logs/modelsï¼Œæ— é¢å¤–æ—¶é—´æˆ³ï¼‰
        self.config_dir = makedirs(os.path.join(self.exp_dir, 'config'))
        self.log_dir = makedirs(os.path.join(self.exp_dir, 'logs'))
        self.model_dir = makedirs(os.path.join(self.exp_dir, 'models'))
        
        # 4. å®šä¹‰æ— æ—¶é—´æˆ³çš„æ–‡ä»¶è·¯å¾„ï¼ˆå®Œå…¨åŒ¹é…è¦æ±‚ï¼Œä¸å‚è€ƒä»£ç ä¸€è‡´ï¼‰
        self.train_config_path = os.path.join(self.config_dir, 'train_config.json')
        self.train_log_path = os.path.join(self.log_dir, 'train_log.json')
        self.best_model_path = os.path.join(self.model_dir, 'best_model.pth')
        self.checkpoint_prefix = os.path.join(self.model_dir, 'checkpoint_epoch')
        # æ–°å¢ï¼šæ˜¾å­˜/æ—¶é—´ç»Ÿè®¡ç»“æœä¿å­˜è·¯å¾„
        self.resource_log_path = os.path.join(self.log_dir, 'resource_stats.json')
        
        # 5. å½’æ¡£å½“å‰ç”Ÿæ•ˆé…ç½®ï¼ˆæ— æ—¶é—´æˆ³ï¼Œç¬¦åˆç›®å½•å†…æ–‡ä»¶å‘½åè¦æ±‚ï¼‰
        with open(self.train_config_path, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, indent=4, ensure_ascii=False)
        
        print(f"âœ… å®éªŒç›®å½•åˆ›å»ºå®Œæˆï¼š{self.exp_dir}")
        print(f"âœ… é…ç½®æ–‡ä»¶å½’æ¡£è‡³ï¼š{self.train_config_path}")
        print(f"âœ… æ¨¡å‹å°†ä¿å­˜è‡³ï¼š{self.model_dir}")
        print(f"âœ… æ—¥å¿—å°†ä¿å­˜è‡³ï¼š{self.log_dir}")
        print(f"âœ… å…¨å±€æ± åŒ–ç±»å‹é…ç½®ï¼š{self.config.get('pool_type', 'add')}")
        print(f"âœ… å­¦ä¹ ç‡ç­–ç•¥ï¼š{self.lr_scheduler_type}ï¼ˆå‚æ•°ä»YAMLé…ç½®åŠ è½½ï¼‰")
        print(f"âœ… æœ€ä¼˜æ¨¡å‹è®°å½•èµ·å§‹è½®æ•°ï¼š{self.best_model_start_epoch} è½®ï¼ˆå‰{self.best_model_start_epoch-1}è½®ä¸æ›´æ–°æœ€ä½³æ¨¡å‹ï¼‰")
        print(f"âœ… ä¸€è‡´æ€§æŸå¤±é…ç½®ï¼š50è½®åå¯ç”¨ï¼Œæƒé‡ {self.config.get('consistency_weight', 1.0)}")

    def _build_dataset(self):
        """æ„å»ºå¹¶åˆ’åˆ†æ•°æ®é›†ï¼ˆä¿®æ”¹ï¼šä»…åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œå–æ¶ˆæµ‹è¯•é›†ï¼‰"""
        # æ•°æ®é›†ä¿å­˜è·¯å¾„ï¼ˆYAMLæœªæŒ‡å®šï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼Œç¡®ä¿ç›®å½•å­˜åœ¨ï¼‰
        self.dataset_save_path = "./dataset/graph_data_with_lappe_and_node_labels"
        makedirs(self.dataset_save_path)
        
        print(f"\n===== æ„å»º/åŠ è½½å«å¯¹æ•°æ ‡ç­¾çš„æ•°æ®é›†ï¼ˆä¿å­˜è‡³ï¼š{self.dataset_save_path}ï¼‰ =====")
        builder = GraphDataBuilder(
            gdp_file_path=self.config['gdp_file_path'],
            patch_size=self.config['patch_size'],
            lap_pe_k=self.config['lap_pe_k']
        )
        
        dataset = builder.build_graph_dataset(
            features_dir=self.config.get('features_dir', './features'),
            output_dir=self.dataset_save_path,
            stride=self.config['stride'],
            max_counties=self.config['max_counties'],
            random_patches=False,
            min_nodes_threshold=self.config['min_nodes_threshold']
        )
        
        if dataset is None:
            raise ValueError("âŒ æ•°æ®é›†æ„å»ºå¤±è´¥æˆ–ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„ä¸é…ç½®")
        
        # ã€æ ¸å¿ƒä¿®æ”¹1ã€‘ä»…åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆå–æ¶ˆæµ‹è¯•é›†åˆ’åˆ†ï¼‰
        unique_counties = list(set(builder.patch_county_mapping))
        unique_counties.sort()  # é»˜è®¤æŒ‰å­—ç¬¦ä¸²å­—å…¸åºæ’åºï¼ˆå¿åé€šå¸¸æ˜¯å­—ç¬¦ä¸²ï¼Œæ•ˆæœç¨³å®šï¼‰
        from sklearn.model_selection import train_test_split
        train_counties, val_counties = train_test_split(
            unique_counties,
            test_size=self.config['val_size'],
            random_state=self.config['random_state']
        )
        
        # æ ¹æ®å¿åˆ’åˆ†æ•°æ®é›†
        train_indices = [i for i, county in enumerate(builder.patch_county_mapping) 
                        if county in train_counties]
        val_indices = [i for i, county in enumerate(builder.patch_county_mapping) 
                      if county in val_counties]
        
        # åˆ›å»ºå­æ•°æ®é›†
        train_dataset = dataset.subset(train_indices)
        val_dataset = dataset.subset(val_indices)
        
        # æ‰“å°åˆ’åˆ†ç»“æœ
        print(f"ğŸ“Š æŒ‰å¿åˆ’åˆ†æ•°æ®é›†ï¼ˆä»…è®­ç»ƒ/éªŒè¯ï¼‰:")
        print(f"  è®­ç»ƒå¿: {len(train_counties)} ä¸ª, å›¾å—: {len(train_indices)} ä¸ª")
        print(f"  éªŒè¯å¿: {len(val_counties)} ä¸ª, å›¾å—: {len(val_indices)} ä¸ª")
        
        return train_dataset, val_dataset

    def _build_dataloaders(self):
        """æ„å»ºæ•°æ®åŠ è½½å™¨ï¼ˆä»…åˆ›å»ºè®­ç»ƒé›†å’ŒéªŒè¯é›†åŠ è½½å™¨ï¼Œå–æ¶ˆæµ‹è¯•é›†ï¼‰"""
        print(f"\n===== åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆæ”¯æŒå˜é•¿å›¾ + å¯¹æ•°åŒæ ‡ç­¾ï¼‰ =====")
        loader_manager = GraphDataLoaderManager(
            batch_size=self.config['batch_size'],
            num_workers=self.config['num_workers']
        )
        
        # ä»…ä¼ å…¥è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œå–æ¶ˆæµ‹è¯•é›†
        data_loaders = loader_manager.create_data_loaders(
            train_dataset=self.train_dataset,
            val_dataset=self.val_dataset,
            test_dataset=None,
            shuffle_train=True
        )
        
        # ä»…è¿”å›è®­ç»ƒåŠ è½½å™¨å’ŒéªŒè¯åŠ è½½å™¨
        return data_loaders['train'], data_loaders['val']

    def _build_model_components(self):
        """æ„å»ºæ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨ï¼ˆä»YAMLåŠ è½½å­¦ä¹ ç‡ç­–ç•¥ä¸å‚æ•°ï¼Œæ–°å¢ä¸€è‡´æ€§æŸå¤±æƒé‡ï¼‰"""
        print(f"\n===== åˆå§‹åŒ–æ¨¡å‹ã€ä¼˜åŒ–å™¨ä¸é…ç½®åŒ–å­¦ä¹ ç‡è°ƒåº¦å™¨ =====")
        
        # -------------------------- æ ¸å¿ƒä¿®æ”¹ï¼šåŠ¨æ€é€‰æ‹©æ¨¡å‹ --------------------------
        # 1. å®šä¹‰æ¨¡å‹æ˜ å°„ï¼ˆæ–°å¢GraphGPSå’ŒGraphormerï¼‰
        model_mapping = {
            "GraphGDP": GraphGDP,
            "GraphGDP_GCN": GraphGDP_GCN,
            "GraphGDP_GraphGPS": GraphGDP_GraphGPS,  # æ–°å¢GraphGPSæ¨¡å‹
            "GraphGDP_Graphormer": GraphGDP_Graphormer  # æ–°å¢Graphormeræ¨¡å‹
        }

        # 2. è·å–å¹¶æ ¡éªŒé…ç½®ä¸­çš„æ¨¡å‹ç±»å‹
        model_cls_name = self.config.get("model_cls", "GraphGDP")  # é»˜è®¤ä½¿ç”¨GraphGDP
        supported_models = list(model_mapping.keys())
        if model_cls_name not in model_mapping:
            raise ValueError(f"âŒ ä»…æ”¯æŒ model_cls={'/'.join(supported_models)}ï¼Œå½“å‰é…ç½®ä¸ºï¼š{model_cls_name}")
        model_cls = model_mapping[model_cls_name]
        print(f"ğŸ“Œ åˆå§‹åŒ–æ¨¡å‹ç±»å‹ï¼š{model_cls_name}")

        # 3. å‡†å¤‡æ¨¡å‹é€šç”¨å‚æ•°
        base_model_kwargs = {
            "channels": self.config['channels'],
            "pe_dim": self.config['pe_dim'],
            "num_layers": self.config['num_layers'],
            "use_rw_pe": self.config['use_rw_pe'],
            "use_lap_pe": self.config['use_lap_pe'],
            "use_grid_pe": self.config['use_grid_pe'],
            "node_dim": self.config['node_dim'],
            "edge_dim": self.config['edge_dim'],
            "if_pool": self.config['if_pool'],
            "pool_type": self.config.get('pool_type', 'add'),
            "drop": self.config['drop'],
            "node_label_dim": self.config['node_label_dim'],
            "global_label_dim": self.config['global_label_dim']
        }

        # 4. ä¸ºä¸åŒæ¨¡å‹è¡¥å……ä¸“å±å‚æ•°
        model_kwargs = base_model_kwargs.copy()

        if model_cls_name == "GraphGDP":
            # GraphGDPï¼ˆMambaç‰ˆï¼‰ä¸“å±å‚æ•°
            model_kwargs.update({
                "model_type": self.config['model_type'],
                "shuffle_ind": self.config['shuffle_ind'],
                "d_state": self.config['d_state'],
                "d_conv": self.config['d_conv'],
                "order_by_degree": self.config['order_by_degree']
            })
        elif model_cls_name == "GraphGDP_GraphGPS":
            # GraphGPSï¼ˆGINE+Performerï¼‰ä¸“å±å‚æ•°
            model_kwargs.update({
                "performer_heads": self.config.get('performer_heads', 4),  # é»˜è®¤4å¤´
                "performer_dim_head": self.config.get('performer_dim_head', 32),  # é»˜è®¤dim_head=32
                "performer_depth": self.config.get('performer_depth', 1)  # Performerå¿…å¡«çš„depthå‚æ•°
            })
        elif model_cls_name == "GraphGDP_Graphormer":
            # Graphormerä¸“å±å‚æ•°
            model_kwargs.update({
                "graphormer_heads": self.config.get('graphormer_heads', 8)  # é»˜è®¤8å¤´æ³¨æ„åŠ›
            })
        # GraphGDP_GCNæ— ä¸“å±å‚æ•°ï¼Œæ— éœ€é¢å¤–è¡¥å……

        # 5. åˆå§‹åŒ–æ¨¡å‹
        model = model_cls(**model_kwargs).to(self.device)
        
        # åˆå§‹åŒ–æŸå¤±å‡½æ•°ï¼ˆæ–°å¢ï¼šä¼ å…¥ä¸€è‡´æ€§æŸå¤±æƒé‡ï¼‰
        criterion = DualRegressionLoss(
            node_weight=self.config['node_loss_weight'],
            global_weight=self.config['global_loss_weight'],
            consistency_weight=self.config.get('consistency_weight', 1.0)  # æ–°å¢ï¼šä¸€è‡´æ€§æŸå¤±æƒé‡ï¼Œé»˜è®¤1.0
        )
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        optimizer = optim.AdamW(
            model.parameters(),
            lr=self.config['learning_rate'],
            weight_decay=self.config['weight_decay']
        )
        
        # ã€æ ¸å¿ƒä¿®æ”¹ã€‘ä»YAMLåŠ è½½å­¦ä¹ ç‡ç­–ç•¥ä¸å‚æ•°ï¼Œæ”¯æŒåŠ¨æ€åˆ‡æ¢
        scheduler = None
        if self.lr_scheduler_type == 'ReduceLROnPlateau':
            # åŠ è½½ReduceLROnPlateauä¸“å±å‚æ•°ï¼ˆä»YAMLè¯»å–ï¼Œå¸¦é»˜è®¤å€¼ï¼‰
            scheduler = ReduceLROnPlateau(
                optimizer,
                mode=self.config.get('lr_scheduler_mode', 'max'),
                factor=self.config.get('lr_scheduler_factor', 0.7),
                patience=self.config.get('lr_scheduler_patience', 10),
                min_lr=self.config.get('lr_scheduler_min_lr', 1e-6)
            )
            print(f"ğŸ“Œ å·²åˆå§‹åŒ– ReduceLROnPlateau è°ƒåº¦å™¨ï¼Œå‚æ•°ï¼š")
            print(f"   - mode: {self.config.get('lr_scheduler_mode', 'max')}")
            print(f"   - factor: {self.config.get('lr_scheduler_factor', 0.7)}")
            print(f"   - patience: {self.config.get('lr_scheduler_patience', 10)}")
            print(f"   - min_lr: {self.config.get('lr_scheduler_min_lr', 1e-6)}")
        elif self.lr_scheduler_type == 'StepLR':
            # åŠ è½½StepLRä¸“å±å‚æ•°ï¼ˆä»YAMLè¯»å–ï¼Œå¸¦é»˜è®¤å€¼ï¼‰
            scheduler = StepLR(
                optimizer,
                step_size=self.config.get('lr_scheduler_step_size', 30),
                gamma=self.config.get('lr_scheduler_gamma', 0.5),
                verbose=self.config.get('lr_scheduler_verbose', True)
            )
            print(f"ğŸ“Œ å·²åˆå§‹åŒ– StepLR è°ƒåº¦å™¨ï¼Œå‚æ•°ï¼š")
            print(f"   - step_size: {self.config.get('lr_scheduler_step_size', 30)}")
            print(f"   - gamma: {self.config.get('lr_scheduler_gamma', 0.5)}")
        else:
            raise ValueError(f"âŒ ä¸æ”¯æŒçš„å­¦ä¹ ç‡ç­–ç•¥ï¼š{self.lr_scheduler_type}ï¼Œå¯é€‰ï¼š['ReduceLROnPlateau', 'StepLR']")
        
        # æ‰“å°é¢„è®­ç»ƒé…ç½®æ‘˜è¦
        print(f"\nğŸ“Œ é¢„è®­ç»ƒæ¨¡å‹é…ç½®æ‘˜è¦ï¼š")
        print(f"   - æ˜¯å¦åŠ è½½é¢„è®­ç»ƒï¼š{self.config['load_pretrained']}")
        if self.config['load_pretrained']:
            print(f"   - é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼š{self.config['pretrained_model_path']}")
            print(f"   - å¤šGPUåŠ è½½ï¼š{self.config['multi_gpu']}")
        
        # æ‰“å°ä¸€è‡´æ€§æŸå¤±é…ç½®
        print(f"\nğŸ“Œ ä¸€è‡´æ€§æŸå¤±é…ç½®æ‘˜è¦ï¼š")
        print(f"   - èŠ‚ç‚¹æŸå¤±æƒé‡ï¼š{self.config['node_loss_weight']}")
        print(f"   - å…¨å±€æŸå¤±æƒé‡ï¼š{self.config['global_loss_weight']}")
        print(f"   - ä¸€è‡´æ€§æŸå¤±æƒé‡ï¼š{self.config.get('consistency_weight', 1.0)}")
        print(f"   - å¯ç”¨æ—¶æœºï¼šç¬¬50è½®åŠä»¥åï¼ˆå‰49è½®ä¸è®¡ç®—ä¸€è‡´æ€§æŸå¤±ï¼‰")
        
        return model, criterion, optimizer, scheduler

    def _load_train_log(self):
        """åŠ è½½å·²æœ‰è®­ç»ƒæ—¥å¿—ï¼ˆè‹¥å­˜åœ¨ï¼‰"""
        if os.path.exists(self.train_log_path):
            with open(self.train_log_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return []

    def _save_train_log(self):
        """ä¿å­˜è®­ç»ƒæ—¥å¿—ï¼ˆæ— æ—¶é—´æˆ³ï¼Œç¬¦åˆç›®å½•å†…æ–‡ä»¶å‘½åè¦æ±‚ï¼‰"""
        with open(self.train_log_path, 'w', encoding='utf-8') as f:
            json.dump(self.train_log, f, indent=4, ensure_ascii=False)

    def _save_resource_stats(self):
        """ä¿å­˜æ˜¾å­˜/æ—¶é—´ç»Ÿè®¡ç»“æœï¼ˆè®­ç»ƒç»“æŸåè°ƒç”¨ï¼‰"""
        # è½¬æ¢æ€»æ—¶é—´å•ä½
        total_time_units = convert_time_units(self.total_training_time)
        # è½¬æ¢å¹³å‡æ¯è½®æ—¶é—´å•ä½
        avg_epoch_seconds = np.mean(self.epoch_train_times) if self.epoch_train_times else 0.0
        avg_epoch_time_units = convert_time_units(avg_epoch_seconds)
        
        resource_stats = {
            'device': str(self.device),
            'total_training_time': total_time_units,
            'avg_epoch_training_time': avg_epoch_time_units,
            'epoch_train_times_seconds': self.epoch_train_times,
            'max_gpu_memory_used_mb': self.max_gpu_memory_used,
            'epoch_gpu_memories_mb': self.epoch_gpu_memories,
            'total_epochs_completed': len(self.epoch_train_times),
            'best_val_r2': self.best_val_r2,
            'best_model_start_epoch': self.best_model_start_epoch,
            'timestamp': self.timestamp,
            'consistency_weight': self.config.get('consistency_weight', 1.0),
            'consistency_enable_epoch': 50  # æ–°å¢ï¼šè®°å½•ä¸€è‡´æ€§æŸå¤±å¯ç”¨è½®æ•°
        }
        
        with open(self.resource_log_path, 'w', encoding='utf-8') as f:
            json.dump(resource_stats, f, indent=4, ensure_ascii=False)

    def _save_checkpoint(self, is_best=False):
        """ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹ï¼ˆæ— æ—¶é—´æˆ³ï¼ŒåŒ¹é…å‚è€ƒä»£ç é£æ ¼ï¼‰"""
        checkpoint_dict = {
            'epoch': self.epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,
            'best_val_r2': self.best_val_r2,
            'best_model_start_epoch': self.best_model_start_epoch,
            'timestamp': self.timestamp,
            'config': self.config,
            'max_gpu_memory_used_mb': self.max_gpu_memory_used,
            'total_training_time_seconds': self.total_training_time,
            'consistency_enable_epoch': 50  # æ–°å¢ï¼šè®°å½•ä¸€è‡´æ€§æŸå¤±å¯ç”¨è½®æ•°
        }
        
        if is_best:
            torch.save(checkpoint_dict, self.best_model_path)
            print(f"âœ… æœ€ä½³æ¨¡å‹å·²ä¿å­˜è‡³ï¼š{self.best_model_path}ï¼ˆåŸºäºéªŒè¯é›†RÂ²æœ€ä¼˜ï¼Œâ‰¥{self.best_model_start_epoch}è½®ï¼‰")
        else:
            checkpoint_path = f'{self.checkpoint_prefix}_{self.epoch}.pth'
            torch.save(checkpoint_dict, checkpoint_path)
            print(f"âœ… æ™®é€šæ£€æŸ¥ç‚¹å·²ä¿å­˜è‡³ï¼š{checkpoint_path}")

    def _process_batch(self, batch):
        """å¤„ç†æ‰¹æ¬¡æ•°æ®ï¼ˆæ ¸å¿ƒï¼šæ­£ç¡®æå–æ•°æ®ä»£ç ä¸­å·²å­˜å‚¨çš„å¯¹æ•°æ ‡ç­¾ï¼Œä¸åšå¤šä½™è®¡ç®—ï¼Œè¿”å›batch_idxï¼‰"""
        # æŠŠbatchå¯¹è±¡ç§»è‡³è®¾å¤‡
        batch = batch.to(self.device)
        
        # æå–åŸºç¡€æ•°æ®
        x = batch.x
        edge_index = batch.edge_index
        batch_idx = batch.batch  # ä¿ç•™batch_idxï¼Œç”¨äºæŒ‰å›¾å—èšåˆèŠ‚ç‚¹
        
        # å¤„ç†edge_attrå ä½ç¬¦ï¼ˆå…¼å®¹æœ‰/æ— è¾¹å±æ€§ï¼‰
        if hasattr(batch, 'edge_attr') and batch.edge_attr is not None and batch.edge_attr.nelement() > 0:
            edge_attr = batch.edge_attr
        else:
            edge_dim = self.config.get('edge_dim', 1)
            edge_attr = torch.zeros((edge_index.shape[1], edge_dim), device=self.device)
        
        # å¤„ç†LapPEç¼–ç ï¼ˆå…¼å®¹æ— LapPEçš„æƒ…å†µï¼‰
        if hasattr(batch, 'lap_pe') and batch.lap_pe is not None:
            lap_pe = batch.lap_pe
        else:
            lap_pe = torch.zeros((batch.num_nodes, self.config['pe_dim']), device=self.device)
        
        # æå–èŠ‚ç‚¹çº§å¯¹æ•°æ ‡ç­¾
        if hasattr(batch, 'y_node') and batch.y_node is not None and batch.y_node.dim() == 2:
            node_target = batch.y_node[:, 1:2]
        else:
            raise ValueError("âŒ æœªæ‰¾åˆ°èŠ‚ç‚¹çº§æ ‡ç­¾ï¼ˆy_nodeï¼‰ï¼Œæˆ–æ ‡ç­¾ç»´åº¦ä¸æ­£ç¡®ï¼Œè¯·æ£€æŸ¥æ•°æ®æ„å»ºä»£ç ")
        
        # æå–å›¾å—çº§å¯¹æ•°æ ‡ç­¾
        if hasattr(batch, 'y') and batch.y is not None and batch.y.dim() == 2:
            global_target = batch.y[:, 1:2]
        else:
            raise ValueError("âŒ æœªæ‰¾åˆ°å›¾å—çº§æ ‡ç­¾ï¼ˆyï¼‰ï¼Œæˆ–æ ‡ç­¾ç»´åº¦ä¸æ­£ç¡®ï¼Œè¯·æ£€æŸ¥æ•°æ®æ„å»ºä»£ç ")
        
        # æ–°å¢ï¼šè¿”å›batch_idx
        return x, edge_index, edge_attr, lap_pe, batch_idx, node_target, global_target

    def train_one_epoch(self):
        """è®­ç»ƒå•ä¸ªEpochï¼ˆ50è½®åå¯ç”¨ä¸€è‡´æ€§æŸå¤±ï¼Œæ ¹æ®å­¦ä¹ ç‡ç­–ç•¥åˆ¤æ–­æ˜¯å¦è°ƒç”¨scheduler.step()ï¼‰"""
        self.model.train()
        meters = {
            'total_loss': AverageMeter(),
            'node_loss': AverageMeter(),
            'global_loss': AverageMeter(),
            'consistency_loss': AverageMeter(),  # æ–°å¢ï¼šä¸€è‡´æ€§æŸå¤±ç»Ÿè®¡
            'node_r2': AverageMeter(),
            'global_r2': AverageMeter(),
            'node_mae': AverageMeter(),
            'global_mae': AverageMeter()
        }
        
        # æ ¸å¿ƒé€»è¾‘ï¼š50è½®åå¯ç”¨ä¸€è‡´æ€§æŸå¤±
        enable_consistency = self.epoch >= 50
        consistency_status = "Enabled" if enable_consistency else "Disabled"
        
        pbar = tqdm(self.train_loader, desc=f'Train Epoch {self.epoch}/{self.config["epochs"]} (Consist: {consistency_status})')
        for batch in pbar:
            # å¤„ç†æ‰¹æ¬¡æ•°æ®ï¼ˆè·å–batch_idxï¼‰
            x, edge_index, edge_attr, lap_pe, batch_idx, node_target, global_target = self._process_batch(batch)
            
            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            node_pred, global_pred = self.model(
                x=x, edge_index=edge_index, edge_attr=edge_attr, batch=batch_idx, lap_pe=lap_pe
            )
            # æ–°å¢ï¼šä¼ å…¥enable_consistencyï¼Œæ§åˆ¶æ˜¯å¦è®¡ç®—ä¸€è‡´æ€§æŸå¤±
            total_loss, node_loss, global_loss, consistency_loss = self.criterion(
                node_pred, node_target, global_pred, global_target, batch_idx, enable_consistency
            )
            
            # è®¡ç®—è¯„ä»·æŒ‡æ ‡
            node_r2 = r2_score(node_pred, node_target).item()
            global_r2 = r2_score(global_pred, global_target).item()
            node_mae = mae_score(node_pred, node_target).item()
            global_mae = mae_score(global_pred, global_target).item()
            
            # åå‘ä¼ æ’­
            total_loss.backward()
            self.optimizer.step()
            
            # æ›´æ–°æŒ‡æ ‡ï¼ˆæ–°å¢ï¼šä¸€è‡´æ€§æŸå¤±ï¼‰
            batch_size = batch.num_graphs
            meters['total_loss'].update(total_loss.item(), batch_size)
            meters['node_loss'].update(node_loss.item(), batch_size)
            meters['global_loss'].update(global_loss.item(), batch_size)
            meters['consistency_loss'].update(consistency_loss.item(), batch_size)  # æ–°å¢
            meters['node_r2'].update(node_r2, batch_size)
            meters['global_r2'].update(global_r2, batch_size)
            meters['node_mae'].update(node_mae, batch_size)
            meters['global_mae'].update(global_mae, batch_size)
            
            # æ›´æ–°è¿›åº¦æ¡ï¼ˆæ–°å¢ï¼šä¸€è‡´æ€§æŸå¤±å±•ç¤ºï¼‰
            pbar.set_postfix({
                'Total Loss': f'{meters["total_loss"].val:.6f}',
                'Node Loss': f'{meters["node_loss"].val:.6f}',
                'Global Loss': f'{meters["global_loss"].val:.6f}',
                'Consist Loss': f'{meters["consistency_loss"].val:.6f}',  # æ–°å¢
                'Node RÂ²': f'{meters["node_r2"].val:.6f}',
                'Global RÂ²': f'{meters["global_r2"].val:.6f}',
                'Node MAE': f'{meters["node_mae"].val:.6f}',
                'Global MAE': f'{meters["global_mae"].val:.6f}'
            })
        
        # ã€æ ¸å¿ƒåˆ¤æ–­ã€‘ä»…StepLRåœ¨è®­ç»ƒåè°ƒç”¨scheduler.step()ï¼ŒReduceLROnPlateauåœ¨éªŒè¯åè°ƒç”¨
        if self.lr_scheduler_type == 'StepLR' and self.scheduler:
            self.scheduler.step()
        
        # æ‰“å°è®­ç»ƒç»“æœï¼ˆæ–°å¢ï¼šä¸€è‡´æ€§æŸå¤± + å¯ç”¨çŠ¶æ€ï¼‰
        print(f"\nTrain Epoch [{self.epoch}/{self.config['epochs']}] (Consist: {consistency_status})")
        print(f"  æ€»æŸå¤±: {meters['total_loss'].avg:.6f} | èŠ‚ç‚¹æŸå¤±: {meters['node_loss'].avg:.6f} | å…¨å±€æŸå¤±: {meters['global_loss'].avg:.6f} | ä¸€è‡´æ€§æŸå¤±: {meters['consistency_loss'].avg:.6f}")
        print(f"  èŠ‚ç‚¹ RÂ²: {meters['node_r2'].avg:.6f} | å…¨å±€ RÂ²: {meters['global_r2'].avg:.6f}")
        print(f"  èŠ‚ç‚¹ MAE: {meters['node_mae'].avg:.6f} | å…¨å±€ MAE: {meters['global_mae'].avg:.6f}")
        
        # è®¡ç®—å¹³å‡RÂ²
        avg_r2 = (meters['node_r2'].avg + meters['global_r2'].avg) / 2
        
        return {
            'loss': meters['total_loss'].avg,
            'node_loss': meters['node_loss'].avg,
            'global_loss': meters['global_loss'].avg,
            'consistency_loss': meters['consistency_loss'].avg,  # æ–°å¢
            'node_r2': meters['node_r2'].avg,
            'global_r2': meters['global_r2'].avg,
            'avg_r2': avg_r2,
            'node_mae': meters['node_mae'].avg,
            'global_mae': meters['global_mae'].avg,
            'consistency_enabled': enable_consistency  # æ–°å¢ï¼šè®°å½•å¯ç”¨çŠ¶æ€
        }

    def evaluate(self, mode='val'):
        """è¯„ä¼°æ¨¡å‹ï¼ˆä»…æ”¯æŒéªŒè¯é›†è¯„ä¼°ï¼Œ50è½®åå¯ç”¨ä¸€è‡´æ€§æŸå¤±ï¼Œè¿”å›å¹³å‡RÂ²ç”¨äºå­¦ä¹ ç‡è°ƒåº¦ï¼‰"""
        self.model.eval()
        meters = {
            'total_loss': AverageMeter(),
            'node_loss': AverageMeter(),
            'global_loss': AverageMeter(),
            'consistency_loss': AverageMeter(),  # æ–°å¢ï¼šä¸€è‡´æ€§æŸå¤±ç»Ÿè®¡
            'node_r2': AverageMeter(),
            'global_r2': AverageMeter(),
            'node_mae': AverageMeter(),
            'global_mae': AverageMeter()
        }
        
        # æ ¸å¿ƒé€»è¾‘ï¼š50è½®åå¯ç”¨ä¸€è‡´æ€§æŸå¤±ï¼ˆä¸è®­ç»ƒä¿æŒä¸€è‡´ï¼‰
        enable_consistency = self.epoch >= 50
        consistency_status = "Enabled" if enable_consistency else "Disabled"
        
        # ä»…æ”¯æŒéªŒè¯é›†
        data_loader = self.val_loader
        pbar = tqdm(data_loader, desc=f'{mode.capitalize()} Epoch {self.epoch} (Consist: {consistency_status})')
        
        with torch.no_grad():
            for batch in pbar:
                # å¤„ç†æ‰¹æ¬¡æ•°æ®ï¼ˆè·å–batch_idxï¼‰
                x, edge_index, edge_attr, lap_pe, batch_idx, node_target, global_target = self._process_batch(batch)
                
                # å‰å‘ä¼ æ’­
                node_pred, global_pred = self.model(
                    x=x, edge_index=edge_index, edge_attr=edge_attr, batch=batch_idx, lap_pe=lap_pe
                )
                # æ–°å¢ï¼šä¼ å…¥enable_consistencyï¼Œæ§åˆ¶æ˜¯å¦è®¡ç®—ä¸€è‡´æ€§æŸå¤±
                total_loss, node_loss, global_loss, consistency_loss = self.criterion(
                    node_pred, node_target, global_pred, global_target, batch_idx, enable_consistency
                )
                
                # è®¡ç®—è¯„ä»·æŒ‡æ ‡
                node_r2 = r2_score(node_pred, node_target).item()
                global_r2 = r2_score(global_pred, global_target).item()
                node_mae = mae_score(node_pred, node_target).item()
                global_mae = mae_score(global_pred, global_target).item()
                
                # æ›´æ–°æŒ‡æ ‡ï¼ˆæ–°å¢ï¼šä¸€è‡´æ€§æŸå¤±ï¼‰
                batch_size = batch.num_graphs
                meters['total_loss'].update(total_loss.item(), batch_size)
                meters['node_loss'].update(node_loss.item(), batch_size)
                meters['global_loss'].update(global_loss.item(), batch_size)
                meters['consistency_loss'].update(consistency_loss.item(), batch_size)  # æ–°å¢
                meters['node_r2'].update(node_r2, batch_size)
                meters['global_r2'].update(global_r2, batch_size)
                meters['node_mae'].update(node_mae, batch_size)
                meters['global_mae'].update(global_mae, batch_size)
                
                # æ›´æ–°è¿›åº¦æ¡ï¼ˆæ–°å¢ï¼šä¸€è‡´æ€§æŸå¤±å±•ç¤ºï¼‰
                pbar.set_postfix({
                    'Total Loss': f'{meters["total_loss"].val:.6f}',
                    'Node Loss': f'{meters["node_loss"].val:.6f}',
                    'Global Loss': f'{meters["global_loss"].val:.6f}',
                    'Consist Loss': f'{meters["consistency_loss"].val:.6f}',  # æ–°å¢
                    'Node RÂ²': f'{meters["node_r2"].val:.6f}',
                    'Global RÂ²': f'{meters["global_r2"].val:.6f}',
                    'Node MAE': f'{meters["node_mae"].val:.6f}',
                    'Global MAE': f'{meters["global_mae"].val:.6f}'
                })
        
        # æ‰“å°è¯„ä¼°ç»“æœï¼ˆæ–°å¢ï¼šä¸€è‡´æ€§æŸå¤± + å¯ç”¨çŠ¶æ€ï¼‰
        print(f"\n{mode.capitalize()} Epoch [{self.epoch}/{self.config['epochs']}] (Consist: {consistency_status})")
        print(f"  æ€»æŸå¤±: {meters['total_loss'].avg:.6f} | èŠ‚ç‚¹æŸå¤±: {meters['node_loss'].avg:.6f} | å…¨å±€æŸå¤±: {meters['global_loss'].avg:.6f} | ä¸€è‡´æ€§æŸå¤±: {meters['consistency_loss'].avg:.6f}")
        print(f"  èŠ‚ç‚¹ RÂ²: {meters['node_r2'].avg:.6f} | å…¨å±€ RÂ²: {meters['global_r2'].avg:.6f}")
        print(f"  èŠ‚ç‚¹ MAE: {meters['node_mae'].avg:.6f} | å…¨å±€ MAE: {meters['global_mae'].avg:.6f}")
        
        # è®¡ç®—å¹³å‡RÂ²
        avg_r2 = (meters['node_r2'].avg + meters['global_r2'].avg) / 2
        return {
            'loss': meters['total_loss'].avg,
            'node_loss': meters['node_loss'].avg,
            'global_loss': meters['global_loss'].avg,
            'consistency_loss': meters['consistency_loss'].avg,  # æ–°å¢
            'node_r2': meters['node_r2'].avg,
            'global_r2': meters['global_r2'].avg,
            'avg_r2': avg_r2,
            'node_mae': meters['node_mae'].avg,
            'global_mae': meters['global_mae'].avg,
            'consistency_enabled': enable_consistency  # æ–°å¢ï¼šè®°å½•å¯ç”¨çŠ¶æ€
        }

    def _print_resource_summary(self):
        """è®­ç»ƒç»“æŸåï¼Œæ‰“å°æ˜¾å­˜/æ—¶é—´æ±‡æ€»ï¼ˆè¡¥å……å®Œæ•´æœ€ä¼˜æŒ‡æ ‡ï¼Œå«ä¸€è‡´æ€§æŸå¤±ï¼‰"""
        print("\n" + "="*80)
        print("ğŸ“Š è®­ç»ƒèµ„æºæ¶ˆè€—æ±‡æ€»ï¼ˆä»…æœ€åæ˜¾ç¤ºï¼‰")
        print("="*80)
        
        # è®¾å¤‡ä¿¡æ¯
        print(f"\n1. è®­ç»ƒè®¾å¤‡: {self.device}")
        
        # æ˜¾å­˜ä¿¡æ¯
        if self.device.type == 'cuda':
            print(f"\n2. æ˜¾å­˜å ç”¨ç»Ÿè®¡ï¼ˆå•ä½ï¼šMBï¼‰")
            print(f"   - æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹å³°å€¼æ˜¾å­˜: {self.max_gpu_memory_used} MB")
            print(f"   - æ¯è½®å³°å€¼æ˜¾å­˜èŒƒå›´: {np.min(self.epoch_gpu_memories):.2f} ~ {np.max(self.epoch_gpu_memories):.2f} MB")
            print(f"   - å¹³å‡æ¯è½®å³°å€¼æ˜¾å­˜: {np.mean(self.epoch_gpu_memories):.2f} MB")
        else:
            print(f"\n2. æ˜¾å­˜å ç”¨ç»Ÿè®¡: æœªä½¿ç”¨GPUï¼Œæ— æ˜¾å­˜æ•°æ®")
        
        # æ—¶é—´ä¿¡æ¯
        total_time_units = convert_time_units(self.total_training_time)
        avg_epoch_seconds = np.mean(self.epoch_train_times) if self.epoch_train_times else 0.0
        avg_epoch_time_units = convert_time_units(avg_epoch_seconds)
        
        print(f"\n3. è®­ç»ƒæ—¶é—´ç»Ÿè®¡")
        print(f"   - æ€»è®­ç»ƒæ—¶é—´: {total_time_units['seconds']} ç§’ = {total_time_units['minutes']} åˆ†é’Ÿ = {total_time_units['hours']} å°æ—¶ = {total_time_units['gpu_days']} GPUå¤©")
        print(f"   - å®Œæˆè½®æ•°: {len(self.epoch_train_times)} / {self.config['epochs']}")
        print(f"   - å¹³å‡æ¯è½®æ—¶é—´: {avg_epoch_seconds:.2f} ç§’ = {avg_epoch_time_units['minutes']:.2f} åˆ†é’Ÿ")
        
        # 4. è®­ç»ƒæ•ˆæœæœ€ä¼˜æŒ‡æ ‡ï¼ˆæ ¸å¿ƒï¼šè¡¥å……å®Œæ•´èŠ‚ç‚¹+å…¨å±€ MAE/MSE/RÂ² + ä¸€è‡´æ€§æŸå¤±ï¼‰
        print(f"\n4. è®­ç»ƒæ•ˆæœæœ€ä¼˜æŒ‡æ ‡ï¼ˆå¯¹åº”æœ€ä½³æ¨¡å‹ï¼ŒéªŒè¯é›†ï¼Œâ‰¥{self.best_model_start_epoch}è½®ï¼‰")
        # åå‘æŸ¥æ‰¾æœ€ä¼˜æ¨¡å‹å¯¹åº”çš„å®Œæ•´æ—¥å¿—æ¡ç›®ï¼ˆè§£å†³æµ®ç‚¹ç²¾åº¦é—®é¢˜ï¼‰
        best_log_entry = None
        if self.train_log:
            for log_entry in self.train_log:
                current_val_avg_r2 = log_entry['val']['avg_r2']
                if abs(current_val_avg_r2 - self.best_val_r2) < 1e-8:  # æµ®ç‚¹è¯¯å·®å…¼å®¹
                    best_log_entry = log_entry
                    break
        
        if best_log_entry:
            # æå–å®Œæ•´æœ€ä¼˜æŒ‡æ ‡ï¼ˆèŠ‚ç‚¹çº§+å…¨å±€çº§ï¼ŒMAE/MSE/RÂ² + ä¸€è‡´æ€§æŸå¤±ï¼‰
            val_metrics = best_log_entry['val']
            node_mae = val_metrics['node_mae']
            node_mse = val_metrics['node_loss']  # node_losså³ä¸ºMSEæŸå¤±ï¼ˆæ¨¡å‹ä¼˜åŒ–ç›®æ ‡ï¼‰
            node_r2 = val_metrics['node_r2']
            global_mae = val_metrics['global_mae']
            global_mse = val_metrics['global_loss']  # global_losså³ä¸ºMSEæŸå¤±ï¼ˆæ¨¡å‹ä¼˜åŒ–ç›®æ ‡ï¼‰
            global_r2 = val_metrics['global_r2']
            consistency_loss = val_metrics['consistency_loss']  # æ–°å¢ï¼šä¸€è‡´æ€§æŸå¤±
            consistency_enabled = val_metrics['consistency_enabled']  # æ–°å¢ï¼šå¯ç”¨çŠ¶æ€
            avg_r2 = val_metrics['avg_r2']
            
            # æ ¼å¼åŒ–è¾“å‡ºï¼Œå±‚æ¬¡æ¸…æ™°
            print(f"   - èŠ‚ç‚¹çº§æŒ‡æ ‡:")
            print(f"     Â· èŠ‚ç‚¹MAEï¼ˆå¹³å‡ç»å¯¹è¯¯å·®ï¼‰: {node_mae:.6f}")
            print(f"     Â· èŠ‚ç‚¹MSEï¼ˆå‡æ–¹è¯¯å·®ï¼‰: {node_mse:.6f}")
            print(f"     Â· èŠ‚ç‚¹RÂ²ï¼ˆå†³å®šç³»æ•°ï¼‰: {node_r2:.6f}")
            print(f"   - å…¨å±€çº§æŒ‡æ ‡:")
            print(f"     Â· å…¨å±€MAEï¼ˆå¹³å‡ç»å¯¹è¯¯å·®ï¼‰: {global_mae:.6f}")
            print(f"     Â· å…¨å±€MSEï¼ˆå‡æ–¹è¯¯å·®ï¼‰: {global_mse:.6f}")
            print(f"     Â· å…¨å±€RÂ²ï¼ˆå†³å®šç³»æ•°ï¼‰: {global_r2:.6f}")
            print(f"   - ä¸€è‡´æ€§æŒ‡æ ‡:")
            print(f"     Â· èŠ‚ç‚¹æ±‚å’Œ-å…¨å±€é¢„æµ‹MSEï¼ˆä¸€è‡´æ€§æŸå¤±ï¼‰: {consistency_loss:.6f}")
            print(f"     Â· ä¸€è‡´æ€§æŸå¤±å¯ç”¨çŠ¶æ€: {'Yes' if consistency_enabled else 'No'}")
            print(f"   - ç»¼åˆæŒ‡æ ‡:")
            print(f"     Â· éªŒè¯é›†å¹³å‡RÂ²ï¼ˆèŠ‚ç‚¹RÂ²+å…¨å±€RÂ²å–å¹³å‡ï¼‰: {avg_r2:.6f}")
        else:
            # å…œåº•ï¼šæ— æ—¥å¿—æ—¶ä»…æ˜¾ç¤ºæœ€ä½³å¹³å‡RÂ²
            print(f"   - éªŒè¯é›†å¹³å‡RÂ²ï¼ˆèŠ‚ç‚¹RÂ²+å…¨å±€RÂ²å–å¹³å‡ï¼‰: {self.best_val_r2:.6f}")
            print(f"   - æç¤ºï¼šæœªæ‰¾åˆ°å®Œæ•´æŒ‡æ ‡æ—¥å¿—ï¼Œæˆ–æœªè¾¾åˆ°{self.best_model_start_epoch}è½®æœ€ä¼˜æ¨¡å‹è®°å½•é˜ˆå€¼")
        
        # ä¿å­˜è·¯å¾„
        print(f"\n5. ç»Ÿè®¡ç»“æœä¿å­˜è·¯å¾„")
        print(f"   - æ˜¾å­˜/æ—¶é—´ç»Ÿè®¡: {self.resource_log_path}")
        print(f"   - æœ€ä½³æ¨¡å‹: {self.best_model_path}")
        print("\n" + "="*80)

    def run(self):
        """è¿è¡Œå®Œæ•´è®­ç»ƒæµç¨‹ï¼ˆæ ¹æ®å­¦ä¹ ç‡ç­–ç•¥åŠ¨æ€è°ƒç”¨schedulerï¼Œè®°å½•æ˜¾å­˜/æ—¶é—´ï¼Œ50è½®åå¯ç”¨ä¸€è‡´æ€§æŸå¤±ï¼‰"""
        print(f"\n===== å¼€å§‹è®­ç»ƒå¾ªç¯ï¼ˆå…± {self.config['epochs']} ä¸ª Epochï¼‰ =====")
        print(f"===== è®­ç»ƒç»“æœå°†å½’æ¡£è‡³ï¼š{self.exp_dir} =====")
        print(f"===== å…¨å±€æ± åŒ–ç±»å‹ï¼š{self.config.get('pool_type', 'add')} =====")
        print(f"===== æœ€ä¼˜æ¨¡å‹åˆ¤æ–­ä¾æ®ï¼šéªŒè¯é›†å¹³å‡RÂ²ï¼ˆèŠ‚ç‚¹RÂ²+å…¨å±€RÂ²ï¼‰æœ€å¤§åŒ–ï¼ˆâ‰¥{self.best_model_start_epoch}è½®ç”Ÿæ•ˆï¼‰ =====")
        print(f"===== ä¸€è‡´æ€§æŸå¤±é…ç½®ï¼š50è½®åå¯ç”¨ï¼Œæƒé‡ {self.config.get('consistency_weight', 1.0)} =====")
        
        # è®°å½•æ€»è®­ç»ƒå¼€å§‹æ—¶é—´
        self.total_training_start = time.time()
        
        for self.epoch in range(1, self.config['epochs'] + 1):
            # è®°å½•å•è½®å¼€å§‹æ—¶é—´
            epoch_start = time.time()
            
            # è®­ç»ƒå•è½®
            train_metrics = self.train_one_epoch()
            
            # éªŒè¯å•è½®
            val_metrics = self.evaluate(mode='val')
            
            # ã€æ ¸å¿ƒåˆ¤æ–­ã€‘ä»…ReduceLROnPlateauåœ¨éªŒè¯åè°ƒç”¨ï¼ˆåŸºäºéªŒè¯é›†å¹³å‡RÂ²ï¼‰
            if self.lr_scheduler_type == 'ReduceLROnPlateau' and self.scheduler:
                self.scheduler.step(val_metrics['avg_r2'])
            
            # è®°å½•å•è½®ç»“æŸæ—¶é—´å’Œå³°å€¼æ˜¾å­˜
            epoch_end = time.time()
            epoch_elapsed = epoch_end - epoch_start
            epoch_max_gpu_mem = get_max_gpu_memory_usage(self.device)
            self.epoch_train_times.append(epoch_elapsed)
            self.epoch_gpu_memories.append(epoch_max_gpu_mem)
            if epoch_max_gpu_mem > self.max_gpu_memory_used:
                self.max_gpu_memory_used = epoch_max_gpu_mem
            
            # è®°å½•æ—¥å¿—ï¼ˆæ–°å¢ï¼šä¸€è‡´æ€§æŸå¤± + å¯ç”¨çŠ¶æ€ï¼‰
            log_entry = {
                'epoch': self.epoch,
                'time': epoch_elapsed,
                'lr': self.optimizer.param_groups[0]['lr'],
                'epoch_max_gpu_mem_mb': epoch_max_gpu_mem,
                'train': train_metrics,
                'val': val_metrics
            }
            self.train_log.append(log_entry)
            self._save_train_log()
            
            # ã€æ ¸å¿ƒä¿®æ”¹ã€‘50è½®ä¹‹åæ‰å¼€å§‹åˆ¤æ–­å¹¶æ›´æ–°æœ€ä¼˜æ¨¡å‹
            current_val_avg_r2 = val_metrics['avg_r2']
            if self.epoch >= self.best_model_start_epoch:
                # è¾¾åˆ°é˜ˆå€¼ï¼Œæ­£å¸¸åˆ¤æ–­æœ€ä¼˜æ¨¡å‹
                if current_val_avg_r2 > self.best_val_r2:
                    self.best_val_r2 = current_val_avg_r2
                    self.patience_counter = 0
                    self._save_checkpoint(is_best=True)
                    print(f"ğŸ‰ éªŒè¯é›†å¹³å‡RÂ²æå‡è‡³ï¼š{self.best_val_r2:.6f}ï¼ˆæ›´æ–°æœ€ä½³æ¨¡å‹ï¼Œâ‰¥{self.best_model_start_epoch}è½®ï¼‰")
                else:
                    self.patience_counter += 1
                    print(f"âš ï¸  éªŒè¯é›†RÂ²æœªæå‡ï¼Œè€å¿ƒå€¼ï¼š{self.patience_counter}/{self.config['patience']}ï¼ˆå½“å‰æœ€ä¼˜ï¼š{self.best_val_r2:.6f}ï¼Œâ‰¥{self.best_model_start_epoch}è½®ï¼‰")
                
                # æ—©åœåˆ¤æ–­ï¼ˆä»…åœ¨è¾¾åˆ°æœ€ä¼˜æ¨¡å‹è®°å½•é˜ˆå€¼åç”Ÿæ•ˆï¼‰
                if self.patience_counter >= self.config['patience']:
                    print(f"\n===== æ—©åœè§¦å‘ï¼ˆè€å¿ƒå€¼è€—å°½ï¼Œâ‰¥{self.best_model_start_epoch}è½®ï¼‰=====")
                    print(f"æœ€ä¼˜éªŒè¯é›†å¹³å‡RÂ²ï¼š{self.best_val_r2:.6f}")
                    break
            else:
                # æœªè¾¾åˆ°50è½®ï¼Œä¸æ›´æ–°æœ€ä¼˜æ¨¡å‹ï¼Œä¸è§¦å‘æ—©åœ
                self.patience_counter = 0  # é‡ç½®è€å¿ƒå€¼ï¼Œé¿å…ç´¯ç§¯
                print(f"â„¹ï¸  å½“å‰è½®æ•° {self.epoch} < {self.best_model_start_epoch} è½®ï¼Œæš‚ä¸è®°å½•æœ€ä¼˜æ¨¡å‹ï¼Œä¸è§¦å‘æ—©åœ")
        
        # è®¡ç®—æ€»è®­ç»ƒæ—¶é—´
        self.total_training_time = time.time() - self.total_training_start
        
        # ä¿å­˜èµ„æºç»Ÿè®¡ + æ‰“å°æ±‡æ€»ä¿¡æ¯ï¼ˆä»…æœ€åæ˜¾ç¤ºï¼‰
        self._save_resource_stats()
        self._print_resource_summary()
        
        # è®­ç»ƒç»“æŸæç¤º
        print(f"\n===== è®­ç»ƒæµç¨‹å…¨éƒ¨ç»“æŸ =====")
        if self.best_val_r2 != -float('inf'):
            print(f"âœ… æœ€ä¼˜éªŒè¯é›†å¹³å‡RÂ²ï¼š{self.best_val_r2:.6f}ï¼ˆâ‰¥{self.best_model_start_epoch}è½®ï¼‰")
        else:
            print(f"âœ… è®­ç»ƒå®Œæˆï¼Œä½†æœªè¾¾åˆ°{self.best_model_start_epoch}è½®ï¼Œæ— æœ€ä¼˜æ¨¡å‹è®°å½•")
        print(f"âœ… æœ¬æ¬¡è®­ç»ƒä½¿ç”¨å…¨å±€æ± åŒ–ç±»å‹ï¼š{self.config.get('pool_type', 'add')}")
        print(f"âœ… æœ¬æ¬¡è®­ç»ƒä¸€è‡´æ€§æŸå¤±ï¼š50è½®åå¯ç”¨ï¼Œæƒé‡ {self.config.get('consistency_weight', 1.0)}")
        print(f"âœ… èµ„æºæ¶ˆè€—ç»Ÿè®¡å·²ä¿å­˜è‡³ï¼š{self.log_dir}")


# ==================== ä¸»å‡½æ•°ï¼ˆç®€æ´å°è£…ï¼ŒåŠ è½½é…ç½®å¹¶è¿è¡Œï¼‰ ====================
def main(args):
    """ä¸»å‡½æ•°ï¼ˆåŠ è½½YAMLé…ç½®ï¼Œåˆå§‹åŒ–è®­ç»ƒç¯å¢ƒå¹¶è¿è¡Œï¼‰"""
    print("=" * 60)
    print("åˆå§‹åŒ– GraphGDP è®­ç»ƒç¯å¢ƒ...")
    print("=" * 60)
    
    # åŠ è½½YAMLé…ç½®ï¼ˆå«å­¦ä¹ ç‡ç­–ç•¥ä¸é¢„è®­ç»ƒå‚æ•° + ä¸€è‡´æ€§æŸå¤±æƒé‡ï¼‰
    config = load_yaml_config(args.config_path)
    
    # åˆå§‹åŒ–è®¾å¤‡
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡ï¼š{device}")
    print(f"åŠ è½½é…ç½®æ–‡ä»¶ï¼š{args.config_path}")
    print(f"è¾“å‡ºç›®å½•ï¼ˆYAMLæŒ‡å®šï¼‰ï¼š{config['output_dir']}")
    print(f"éªŒè¯é›†æ¯”ä¾‹ï¼š{config['val_size']}")
    print(f"å…¨å±€æ± åŒ–ç±»å‹ï¼š{config['pool_type']}")
    print(f"å­¦ä¹ ç‡ç­–ç•¥ï¼š{config['lr_scheduler_type']}")
    print(f"ä¸€è‡´æ€§æŸå¤±é…ç½®ï¼š50è½®åå¯ç”¨ï¼Œæƒé‡ {config['consistency_weight']}")
    
    # åˆå§‹åŒ–è®­ç»ƒå™¨å¹¶è¿è¡Œ
    trainer = GraphGDPTrainer(config, device)
    trainer.run()

# ==================== å‘½ä»¤è¡Œå‚æ•°è§£æ ====================
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='GraphGDP åŒå›å½’æ¨¡å‹è®­ç»ƒï¼ˆé…ç½®åŒ–å­¦ä¹ ç‡ç­–ç•¥ + MAE/RÂ² æŒ‡æ ‡ + æ˜¾å­˜/æ—¶é—´ç»Ÿè®¡ + 50è½®åå¯ç”¨ä¸€è‡´æ€§æŸå¤±ï¼‰')
    parser.add_argument('--config_path', type=str, default='config/GraphGDP_config.yaml',
                        help='YAMLé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šconfig/GraphGDP_config.yamlï¼‰')
    
    # è§£æå‚æ•°
    args = parser.parse_args()
    
    # è¿è¡Œä¸»å‡½æ•°
    main(args)
